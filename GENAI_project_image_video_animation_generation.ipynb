{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumit6287/GenAI/blob/main/GENAI_project_image_video_animation_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Title** : **Image/GIF/VIdeo GenAI**\n",
        "\n",
        "# **Project scope:**\n",
        "\n",
        "The project focuses on developing a generative AI system within Google Colab to create images and GIFs using relevant APIs. It will integrate APIs for image generation and processing, employing deep learning models like CNNs. The system will autonomously produce diverse, high-quality visual content, such as landscapes, abstract art, and animations. Evaluation methods will ensure output quality, while ethical considerations guide its responsible use. Ultimately, the project aims to demonstrate the capabilities of AI in generating compelling visual content and advancing the field of generative technology within the constraints of image and GIF generation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWRrPYjU-FnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Group Members :**\n",
        "\n",
        "* Student Name - Deepanshu\n",
        "      Id- 4357353\n",
        "* Student Name - Sumit\n",
        "      Id- 4356287"
      ],
      "metadata": {
        "id": "8ugcCz4l9POS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Detailed Project Description Cell**\n",
        "\"Image/GIF/Video GenAI\" is a Google Colab project that is working on making a creative AI system. It will include APIs for creating and editing images, and deep learning models like CNNs will be used to make diverse, high-quality visual material on their own. It will be used responsibly by taking ethics into account, showing AI's promise in creative technology.\n",
        "## **OBJECTIVES** :\n",
        "1. Use Google Colab to build a strong creative AI system.\n",
        "2. Add the necessary APIs for creating and editing images.\n",
        "3. To make pictures, GIFs, and movies, use deep learning models, especially CNNs.\n",
        "4. Make sure that different kinds of high-quality visual material can be made on their own, such as cartoons, landscapes, and abstract art.\n",
        "5. Use review tools to check the quality of the result and make the creative process better.\n",
        "6. Use social concerns to help you use the AI system in a smart way.\n",
        "7. Show how AI can be used to make interesting graphic material and move the field of creative technology forward.\n",
        "\n",
        "\n",
        "\n",
        "## **OUTCOMES**\n",
        "1. A fully working creative AI system that is used in Google Colab and can make pictures, GIFs, and movies on its own.\n",
        "2. Adding the right APIs for creating and editing images, which makes it easier to make a wide range of visual material.\n",
        "3. The successful use of deep learning models, especially CNNs, to create high-quality visual results in a range of styles and topics.\n",
        "4. A wide range of high-quality graphic material created by the system, such as cartoons, scenery, and abstract art.\n",
        "5. Creating strong review tools to check the quality and variety of the work that is produced, so that it keeps getting better.\n",
        "6. Ethical rules were put in place to make sure the AI system was used responsibly, taking into account possible flaws and the moral consequences.\n",
        "7. A demonstration of how AI can create interesting visual material, showing how generative technology has improved and what it could be used for.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SJNvsyvv-jM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modifications**\n",
        "\n",
        "In the existing project, enhancements will focus on improving output quality and user interaction.Some of the changes include making deep learning models better at generating realistic and diversified GIFs and images. New capabilities, such the ability to personalize content production based on user preferences or themes, will be available in future updates. The models will be improved repeatedly with the help of a feedback system that collects user input. We will continue to prioritize ethical issues and implement additional safeguards to prevent abuse or improper information. The overarching goals of these updates and additions are to improve the user experience, make the system more versatile, and guarantee the appropriate deployment of AI.\n",
        "\n",
        "\n",
        "\n",
        "## **Justification and impacts**\n",
        "\n",
        "Both user satisfaction and system performance are aimed at with these enhancements.\n",
        "\n",
        "- By improving deep learning models to provide more outputs, the study enhances realism and uniqueness.\n",
        "- By allowing users to personalize content, we want to foster engagement and foster a sense of belonging.\n",
        "- Deploying AI while upholding ethical standards fosters confidence and minimizes misuse.\n",
        "- By enhancing the project's content, user engagement, and ethics, these enhancements promote responsible technology use and contribute to the development of generative AI.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DDwC-cRK2C_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criteria-Specific Cell**\n",
        "\n",
        "## **Relevance :**\n",
        "\n",
        "The significance of the project resides in its potential to propel generative AI technology forward by providing inventive resolutions for the generation of visual content. It fulfills the changing needs of users for customizable, superior multimedia while maintaining ethical principles in the advancement of artificial intelligence. Through the provision of varied and authentic outputs that augment user involvement, the project actively contributes to the progression of AI-powered innovation and the conscientious implementation of technology in multimedia applications.\n",
        "\n",
        "\n",
        "##**Applications**\n",
        "AI-Generated Visual Content Applicabilities:\n",
        "• Useful in education, amusement, and marketing sectors.\n",
        "\n",
        "\n",
        "• Marketers can use AI-generated images and GIFs for compelling advertising campaigns.\n",
        "\n",
        "\n",
        "• Provides medium for filmmakers and artists to experiment with visual concepts.\n",
        "\n",
        "\n",
        "• Educators can incorporate content into interactive resources to enhance student engagement.\n",
        "\n",
        "\n",
        "• Offers utility across various sectors seeking advanced multimedia resolutions.\n",
        "\n",
        "## **Innovation**\n",
        "\n",
        "Through its efforts to stretch the limits of generative AI in multimedia production, the project exemplifies innovation. By effectively integrating application programming interfaces (APIs) and deep learning models, it establishes novel approaches to produce varied and lifelike visual content, including GIFs and images. The integration of user customization and feedback mechanisms promotes a heightened level of interactivity and individualization, thereby establishing a model for subsequent progressions in creative technologies powered by artificial intelligence.\n",
        "\n",
        "## **Technical proficiency**\n",
        "\n",
        "By generating high-quality visual content using cutting-edge technologies such as APIs and deep learning models, the initiative demonstrates technical proficiency. By means of rigorous model training and optimization, it exhibits expertise in intricate algorithms utilized for the generation of images and GIFs. Proficient utilization of the Google Colab environment is evidenced by the seamless integration of APIs and the allocation of computational resources and data sources. In general, the project serves as a demonstration of proficiency in employing sophisticated AI methods to attain inventive results in the realm of multimedia development.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6cfvQgVYFl6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Install Replicate**\n",
        "\n",
        "  Execute the provided command to install the Replicate library via pip, enabling access to its functionalities for replication and reproducibility in AI experiments.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vKzL0U3a6wlx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjlbJnxO2w-h",
        "outputId": "33ce8417-2b38-409e-aaf3-026104316bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.25.1-py3-none-any.whl (39 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.6.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.16.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 replicate-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#  **Setting API Token**\n",
        "Assign the provided API token to the environment variable \"REPLICATE_API_TOKEN\" using the `os.environ` method, enabling authentication and access to Replicate services."
      ],
      "metadata": {
        "id": "-EtGiSrD69zX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API = \"r8_0nLaBTkCHjGilEV1ZqqzoHPPrBdF2aV1PVBBy\"\n",
        "import os\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = API\n",
        "#Our API token source : https://replicate.com/signin?next=/account/api-tokens"
      ],
      "metadata": {
        "id": "zX0YyZI_3dx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Generate Content with Prompt**\n",
        "The text outlines the process of defining a prompt for an AI model, which is then executed using the Replicate library. The model, based on a stable diffusion architecture, generates coherent and contextually relevant output. The output is then extracted, capturing its interpretation and extension of the prompt, which can include textual descriptions, images, or multimedia content."
      ],
      "metadata": {
        "id": "sH5YFxFX7NVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"dog chasing a ball in the park\"\n",
        "import replicate\n",
        "output = replicate.run(\n",
        "  \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\",\n",
        "  input={\"prompt\":prompt}\n",
        ")\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9jB54-K3p48",
        "outputId": "dc728a48-c024-4987-962d-b9a207603882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://replicate.delivery/pbxt/9ZMDqGuC54b6HNQgDfIW2cnrDtttmd5V1l3wTk42wJZVNsSJA/out-0.png']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Display Generated Image**\n",
        "\n",
        "   - Import the `Image` class from the IPython display module.\n",
        "   - Assign the generated output to the variable `output_image`.\n",
        "   - Use the `Image` class to display the image from the first element (`output_image[0]`) in the output.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kw6QYycd7SVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "output_image = output\n",
        "Image(url=output_image[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "7JWCVDHf3sYu",
        "outputId": "e39904e9-404c-483c-8aa1-6f43ef22a76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://replicate.delivery/pbxt/9ZMDqGuC54b6HNQgDfIW2cnrDtttmd5V1l3wTk42wJZVNsSJA/out-0.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Generate Video/GIF/Animation**  \n",
        "Utilize the Replicate library to run the specified AI model.\n",
        "\n",
        "Provide input prompts for the start and end frames of the animation: dog chasing a ball in the park\" and \"dog catches the ball and runs away happily\".\n",
        "\n",
        "Specify the desired output format as \"gif\" and enable ping-pong mode for the GIF (`gif_ping_pong`), causing the animation to loop back and forth seamlessly.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U4dvFuOo7oxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "output = replicate.run(\n",
        "    \"andreasjansson/stable-diffusion-animation:ca1f5e306e5721e19c473e0d094e6603f0456fe759c10715fcd6c1b79242d4a5\",\n",
        "    input={\n",
        "        \"prompt_start\": \"dog chasing a ball in the park\",\n",
        "        \"prompt_end\": \"dog catches the ball and runs away happily\",\n",
        "        \"output_format\": \"gif\",\n",
        "        \"gif_ping_pong\": True\n",
        "    }\n",
        ")\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Owfxz0V3uov",
        "outputId": "5df745bb-1019-4e2c-dad8-c0bc5f379106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Prediction.output_iterator at 0x7e966ed04c10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Iterate Through Output**  \n",
        "Iterate through each item in the output variable, potentially containing URLs, metadata, or other information generated by the Replicate API, for further processing or analysis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5G1iqzb-76Jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generate gif\n",
        "for item in output:\n",
        "     #https://replicate.com/andreasjansson/stable-diffusion-animation/versions/ca1f5e306e5721e19c473e0d094e6603f0456fe759c10715fcd6c1b79242d4a5/api#output-schema\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bkyp74E3wcl",
        "outputId": "13bffa2d-9991-4639-ee1c-600ad3b84d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://replicate.delivery/pbxt/zOZg34kbeC12AytbfR7tfmNcyehemMwAtfbpZur7QYB3eSsSJA/video.gif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Extract GIF URL**  \n",
        "Assign the GIF URL to the variable `gif_url` by extracting it from the `item` using slicing, potentially encompassing the entire length of the `item` string.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WK4etb_78Jq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get the video on colab\n",
        "gif_url= item[0:len(item)]"
      ],
      "metadata": {
        "id": "exOI3-Rd3yn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#**Display and Save GIF**  \n",
        "Retrieve the GIF using its URL via an HTTP request. If the request is successful (status code 200), display the GIF in the notebook using IPython's `display` function, save it locally in the Colab environment, and show the saved GIF using the PIL library. If the request fails, print a message indicating the failure.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0J2u0K738Mk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.display import display, Image\n",
        "from PIL import Image as PILImage\n",
        "from io import BytesIO\n",
        "response = requests.get(gif_url)\n",
        "if response.status_code == 200:\n",
        "    # To Ddisplay the GIF in the notebook\n",
        "    display(Image(url=gif_url))\n",
        "\n",
        "    # To save the GIF in the Colab environment\n",
        "    with open(\"gif_output.gif\", \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    # TO show a saved GIF using PIL\n",
        "    saved_gif = PILImage.open(\"gif_output.gif\")\n",
        "    saved_gif.show()\n",
        "else:\n",
        "    print(\"Failed to fetch GIF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "whx-a5Ne319x",
        "outputId": "d39d77b4-e532-4962-f65a-0d01a9c7d34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://replicate.delivery/pbxt/zOZg34kbeC12AytbfR7tfmNcyehemMwAtfbpZur7QYB3eSsSJA/video.gif\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **REFERENCES**\n",
        "\n",
        "* turna1-GenAI-GitHub. https://github.com/turna1/GenAI/blob/main/image_video_animation_generation.ipynb\n",
        "*  ReplicateAI Tokens. https://replicate.com/account/api-tokens\n",
        "* Google Colaboratory. https://colab.research.google.com/\n",
        "---"
      ],
      "metadata": {
        "id": "gdi6nuQbG9U6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **VIDEO PRESENTATION LINK**"
      ],
      "metadata": {
        "id": "NnHs-jd0HCvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Thank You**\n",
        "\n"
      ],
      "metadata": {
        "id": "HyYFTY6SLLok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lhVLG8_Dy79P"
      }
    }
  ]
}